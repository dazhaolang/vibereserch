"""
æ–‡çŒ®è½»ç»“æ„åŒ–æ•°æ®åº“ç³»ç»Ÿ - AIå¯¹è¯åŠ©æ‰‹æ¨¡å—
æä¾›å…¨æµç¨‹æ™ºèƒ½å¼•å¯¼å’Œäº¤äº’æ”¯æŒ
"""

from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import asyncio
import json
from pydantic import BaseModel
from enum import Enum


class TaskStage(Enum):
    """ä»»åŠ¡é˜¶æ®µæšä¸¾"""
    RESEARCH_DIRECTION = "research_direction"
    LITERATURE_COLLECTION = "literature_collection"
    LIGHTWEIGHT_STRUCTURING = "lightweight_structuring"
    EXPERIENCE_ENHANCEMENT = "experience_enhancement"
    SOLUTION_GENERATION = "solution_generation"


class UserLevel(Enum):
    """ç”¨æˆ·ä¸“ä¸šæ°´å¹³æšä¸¾"""
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"
    EXPERT = "expert"


class InteractionRequest(BaseModel):
    """AIäº¤äº’è¯·æ±‚æ¨¡å‹"""
    user_id: str
    session_id: str
    stage: TaskStage
    message: str
    context: Dict[str, Any] = {}
    user_level: Optional[UserLevel] = None


class InteractionResponse(BaseModel):
    """AIäº¤äº’å“åº”æ¨¡å‹"""
    response: str
    suggestions: List[str] = []
    next_actions: List[Dict[str, Any]] = []
    confidence_score: float = 0.0
    requires_confirmation: bool = False
    estimated_time: Optional[int] = None  # é¢„ä¼°æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰


class ResearchDirectionGuide:
    """ç ”ç©¶æ–¹å‘æ™ºèƒ½å¼•å¯¼æ¨¡å—"""
    
    def __init__(self):
        self.domain_keywords = {
            "ææ–™ç§‘å­¦": {
                "çº³ç±³ææ–™": ["çº³ç±³é¢—ç²’", "çº³ç±³ç®¡", "çº³ç±³ç‰‡", "é‡å­ç‚¹"],
                "ç”µæ± ææ–™": ["é”‚ç”µæ± ", "é’ ç”µæ± ", "å›ºæ€ç”µæ± ", "ç”µè§£è´¨"],
                "å‚¬åŒ–ææ–™": ["å…‰å‚¬åŒ–", "ç”µå‚¬åŒ–", "å¼‚ç›¸å‚¬åŒ–", "å•åŸå­å‚¬åŒ–"],
                "å¤åˆææ–™": ["çº¤ç»´å¤åˆ", "é‡‘å±åŸºå¤åˆ", "é™¶ç“·åŸºå¤åˆ", "èšåˆç‰©åŸºå¤åˆ"]
            },
            "åŒ–å­¦": {
                "æœ‰æœºåŒ–å­¦": ["æœ‰æœºåˆæˆ", "è¯ç‰©åŒ–å­¦", "å¤©ç„¶äº§ç‰©", "æœ‰æœºå‚¬åŒ–"],
                "æ— æœºåŒ–å­¦": ["é…ä½åŒ–å­¦", "å›ºä½“åŒ–å­¦", "ææ–™åŒ–å­¦", "ç”Ÿç‰©æ— æœºåŒ–å­¦"],
                "åˆ†æåŒ–å­¦": ["å…‰è°±åˆ†æ", "è‰²è°±åˆ†æ", "ç”µåŒ–å­¦åˆ†æ", "è´¨è°±åˆ†æ"],
                "ç‰©ç†åŒ–å­¦": ["è¡¨é¢åŒ–å­¦", "èƒ¶ä½“åŒ–å­¦", "ç”µåŒ–å­¦", "çƒ­åŒ–å­¦"]
            }
        }
    
    async def analyze_research_direction(self, user_input: str, uploaded_files: List[str] = None) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·ç ”ç©¶æ–¹å‘"""
        # æ¨¡æ‹ŸAIåˆ†æè¿‡ç¨‹
        await asyncio.sleep(0.1)
        
        analysis = {
            "identified_keywords": [],
            "suggested_refinements": [],
            "related_fields": [],
            "confidence": 0.8
        }
        
        # ç®€å•å…³é”®è¯åŒ¹é…ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨æ›´å¤æ‚çš„NLPæ¨¡å‹ï¼‰
        for domain, categories in self.domain_keywords.items():
            for category, keywords in categories.items():
                for keyword in keywords:
                    if keyword.lower() in user_input.lower():
                        analysis["identified_keywords"].append({
                            "keyword": keyword,
                            "domain": domain,
                            "category": category
                        })
        
        # ç”Ÿæˆç»†åŒ–å»ºè®®
        if analysis["identified_keywords"]:
            refinements = []
            for kw in analysis["identified_keywords"][:2]:
                refinements.append(f"å»ºè®®æ˜ç¡®å…·ä½“çš„{kw['keyword']}ç±»å‹")
                refinements.append(f"å¯ä»¥è€ƒè™‘{kw['category']}é¢†åŸŸçš„äº¤å‰ç ”ç©¶")
            analysis["suggested_refinements"] = refinements
        
        return analysis
    
    async def generate_keyword_strategy(self, research_focus: str) -> Dict[str, Any]:
        """ç”Ÿæˆå…³é”®è¯æœç´¢ç­–ç•¥"""
        await asyncio.sleep(0.1)
        
        return {
            "primary_keywords": [research_focus],
            "secondary_keywords": ["synthesis", "characterization", "application"],
            "search_combinations": [
                f"{research_focus} synthesis",
                f"{research_focus} characterization",
                f"{research_focus} properties"
            ],
            "estimated_papers": 2500,
            "recommended_filters": ["recent_5_years", "high_impact"]
        }


class LiteratureQualityAssessor:
    """æ–‡çŒ®è´¨é‡è¯„ä¼°æ¨¡å—"""
    
    async def assess_literature_quality(self, literature_batch: List[Dict]) -> Dict[str, Any]:
        """è¯„ä¼°æ–‡çŒ®è´¨é‡"""
        await asyncio.sleep(0.2)
        
        total_papers = len(literature_batch)
        high_quality = int(total_papers * 0.3)
        medium_quality = int(total_papers * 0.5)
        low_quality = total_papers - high_quality - medium_quality
        
        return {
            "total_papers": total_papers,
            "quality_distribution": {
                "high": high_quality,
                "medium": medium_quality,
                "low": low_quality
            },
            "average_citation": 15.6,
            "recent_papers_ratio": 0.7,
            "top_journals_ratio": 0.4,
            "recommendation": "å»ºè®®ä¿ç•™é«˜è´¨é‡å’Œä¸­ç­‰è´¨é‡æ–‡çŒ®ï¼Œè¿‡æ»¤ä½è´¨é‡æ–‡çŒ®"
        }
    
    async def predict_collection_outcome(self, keywords: List[str]) -> Dict[str, Any]:
        """é¢„æµ‹é‡‡é›†ç»“æœ"""
        await asyncio.sleep(0.1)
        
        return {
            "estimated_total": 3200,
            "estimated_relevant": 2400,
            "estimated_high_quality": 720,
            "estimated_time_minutes": 25,
            "confidence": 0.85,
            "potential_issues": [
                "éƒ¨åˆ†å…³é”®è¯å¯èƒ½è¿‡äºå®½æ³›",
                "å»ºè®®å¢åŠ æ—¶é—´èŒƒå›´é™åˆ¶"
            ]
        }


class StructuringFormatOptimizer:
    """è½»ç»“æ„åŒ–æ ¼å¼ä¼˜åŒ–æ¨¡å—"""
    
    def __init__(self):
        self.domain_templates = {
            "ææ–™ç§‘å­¦": {
                "åˆ¶å¤‡ä¸è¡¨å¾": ["åŸæ–™å‡†å¤‡", "åˆ¶å¤‡æ–¹æ³•", "å·¥è‰ºå‚æ•°", "è¡¨å¾æŠ€æœ¯", "æ€§èƒ½æµ‹è¯•"],
                "åº”ç”¨ç ”ç©¶": ["åº”ç”¨åœºæ™¯", "æ€§èƒ½æŒ‡æ ‡", "å¯¹æ¯”åˆ†æ", "ä¼˜åŒ–ç­–ç•¥"],
                "æœºç†ç ”ç©¶": ["ååº”æœºç†", "è®¡ç®—æ¨¡æ‹Ÿ", "ç†è®ºåˆ†æ", "éªŒè¯å®éªŒ"]
            },
            "åŒ–å­¦": {
                "åˆæˆç ”ç©¶": ["åˆæˆè·¯çº¿", "ååº”æ¡ä»¶", "äº§ç‡ä¼˜åŒ–", "äº§ç‰©åˆ†ç¦»"],
                "åˆ†æè¡¨å¾": ["ç»“æ„ç¡®è®¤", "çº¯åº¦åˆ†æ", "æ€§è´¨æµ‹å®š", "ç¨³å®šæ€§ç ”ç©¶"],
                "æœºç†æ¢ç´¢": ["ååº”æœºç†", "åŠ¨åŠ›å­¦ç ”ç©¶", "çƒ­åŠ›å­¦åˆ†æ", "è®¡ç®—åŒ–å­¦"]
            }
        }
    
    async def generate_structure_template(self, domain: str, literature_sample: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆç»“æ„åŒ–æ¨¡æ¿"""
        await asyncio.sleep(0.1)
        
        template = self.domain_templates.get(domain, self.domain_templates["ææ–™ç§‘å­¦"])
        
        return {
            "template_structure": template,
            "customization_suggestions": [
                "å¯æ ¹æ®å…·ä½“ç ”ç©¶å†…å®¹è°ƒæ•´äºŒçº§åˆ†ç±»",
                "å»ºè®®å¢åŠ 'å®éªŒæ¡ä»¶'å­ç±»åˆ«",
                "å¯è€ƒè™‘æ·»åŠ 'ç»“æœè®¨è®º'æ¿å—"
            ],
            "adaptation_confidence": 0.9,
            "estimated_extraction_time": 45
        }
    
    async def evaluate_structure_fitness(self, structure: Dict, sample_papers: List[Dict]) -> Dict[str, Any]:
        """è¯„ä¼°ç»“æ„é€‚é…æ€§"""
        await asyncio.sleep(0.1)
        
        return {
            "fitness_score": 0.87,
            "coverage_analysis": {
                "well_covered": ["åˆ¶å¤‡æ–¹æ³•", "è¡¨å¾æŠ€æœ¯"],
                "partially_covered": ["æ€§èƒ½æµ‹è¯•"],
                "missing_coverage": ["æˆæœ¬åˆ†æ"]
            },
            "optimization_suggestions": [
                "å»ºè®®åœ¨'åˆ¶å¤‡æ–¹æ³•'ä¸‹å¢åŠ 'è®¾å¤‡è¦æ±‚'å­ç±»",
                "å¯è€ƒè™‘æ·»åŠ 'å•†ä¸šåŒ–å‰æ™¯'åˆ†ææ¿å—"
            ]
        }


class ExperienceEnhancementMonitor:
    """ç»éªŒå¢å¼ºè¿­ä»£ç›‘æ§æ¨¡å—"""
    
    async def monitor_iteration_quality(self, iteration_data: Dict) -> Dict[str, Any]:
        """ç›‘æ§è¿­ä»£è´¨é‡"""
        await asyncio.sleep(0.1)
        
        current_round = iteration_data.get("current_round", 1)
        content_size = iteration_data.get("content_size", 1000)
        
        return {
            "current_round": current_round,
            "quality_score": min(0.6 + current_round * 0.1, 0.95),
            "content_growth_rate": max(0.15 - current_round * 0.02, 0.03),
            "estimated_remaining_rounds": max(8 - current_round, 0),
            "stop_recommendation": current_round >= 3 and (0.15 - current_round * 0.02) < 0.05,
            "improvement_areas": [
                "æœºç†è§£é‡Šéƒ¨åˆ†å¯è¿›ä¸€æ­¥å®Œå–„",
                "å®éªŒå‚æ•°ä¼˜åŒ–å»ºè®®éœ€è¦æ›´å…·ä½“"
            ]
        }
    
    async def predict_final_quality(self, current_state: Dict) -> Dict[str, Any]:
        """é¢„æµ‹æœ€ç»ˆè´¨é‡"""
        await asyncio.sleep(0.1)
        
        return {
            "predicted_final_score": 0.92,
            "estimated_completion_time": 35,
            "expected_improvements": [
                "çŸ¥è¯†è¦†ç›–åº¦å°†æå‡è‡³95%",
                "å®ç”¨æ€§è¯„åˆ†é¢„è®¡è¾¾åˆ°4.5/5",
                "ä¸“å®¶è®¤å¯åº¦é¢„è®¡è¶…è¿‡90%"
            ],
            "confidence": 0.88
        }


class LiteratureAIAssistant:
    """æ–‡çŒ®AIåŠ©æ‰‹ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.research_guide = ResearchDirectionGuide()
        self.quality_assessor = LiteratureQualityAssessor()
        self.format_optimizer = StructuringFormatOptimizer()
        self.enhancement_monitor = ExperienceEnhancementMonitor()
        self.user_sessions = {}  # å­˜å‚¨ç”¨æˆ·ä¼šè¯çŠ¶æ€
    
    async def handle_interaction(self, request: InteractionRequest) -> InteractionResponse:
        """å¤„ç†ç”¨æˆ·äº¤äº’è¯·æ±‚"""
        
        # æ›´æ–°ç”¨æˆ·ä¼šè¯çŠ¶æ€
        if request.session_id not in self.user_sessions:
            self.user_sessions[request.session_id] = {
                "start_time": datetime.now(),
                "stage_history": [],
                "user_level": request.user_level or UserLevel.INTERMEDIATE,
                "context": {}
            }
        
        session = self.user_sessions[request.session_id]
        session["context"].update(request.context)
        
        # æ ¹æ®ä¸åŒé˜¶æ®µå¤„ç†è¯·æ±‚
        if request.stage == TaskStage.RESEARCH_DIRECTION:
            return await self._handle_research_direction(request, session)
        elif request.stage == TaskStage.LITERATURE_COLLECTION:
            return await self._handle_literature_collection(request, session)
        elif request.stage == TaskStage.LIGHTWEIGHT_STRUCTURING:
            return await self._handle_structuring(request, session)
        elif request.stage == TaskStage.EXPERIENCE_ENHANCEMENT:
            return await self._handle_enhancement(request, session)
        elif request.stage == TaskStage.SOLUTION_GENERATION:
            return await self._handle_solution_generation(request, session)
        else:
            return InteractionResponse(
                response="æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†è¿™ä¸ªé˜¶æ®µçš„è¯·æ±‚ã€‚",
                confidence_score=0.0
            )
    
    async def _handle_research_direction(self, request: InteractionRequest, session: Dict) -> InteractionResponse:
        """å¤„ç†ç ”ç©¶æ–¹å‘ç¡®å®šé˜¶æ®µ"""
        
        # åˆ†æç ”ç©¶æ–¹å‘
        analysis = await self.research_guide.analyze_research_direction(request.message)
        
        if analysis["confidence"] < 0.5:
            return InteractionResponse(
                response="æˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥ç†è§£æ‚¨çš„ç ”ç©¶æ–¹å‘ã€‚èƒ½å¦è¯¦ç»†æè¿°ä¸€ä¸‹æ‚¨çš„ç ”ç©¶ç›®æ ‡ï¼Ÿ",
                suggestions=[
                    "è¯·æè¿°å…·ä½“çš„ç ”ç©¶å¯¹è±¡ï¼ˆå¦‚ææ–™ã€åŒ–åˆç‰©ç­‰ï¼‰",
                    "è¯·è¯´æ˜ç ”ç©¶çš„ä¸»è¦ç›®çš„ï¼ˆå¦‚åˆ¶å¤‡ã€è¡¨å¾ã€åº”ç”¨ç­‰ï¼‰",
                    "å¯ä»¥ä¸Šä¼ ç›¸å…³çš„é¡¹ç›®ä¹¦æˆ–ç”³è¯·ä¹¦"
                ],
                requires_confirmation=False,
                confidence_score=analysis["confidence"]
            )
        
        # ç”Ÿæˆå…³é”®è¯ç­–ç•¥
        if analysis["identified_keywords"]:
            main_keyword = analysis["identified_keywords"][0]["keyword"]
            keyword_strategy = await self.research_guide.generate_keyword_strategy(main_keyword)
            
            response = f"æˆ‘ç†è§£æ‚¨çš„ç ”ç©¶æ–¹å‘æ˜¯å…³äº{main_keyword}ã€‚åŸºäºåˆ†æï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†ä»¥ä¸‹æœç´¢ç­–ç•¥ï¼š\n\n"
            response += f"â€¢ ä¸»è¦å…³é”®è¯ï¼š{', '.join(keyword_strategy['primary_keywords'])}\n"
            response += f"â€¢ è¾…åŠ©å…³é”®è¯ï¼š{', '.join(keyword_strategy['secondary_keywords'])}\n"
            response += f"â€¢ é¢„ä¼°å¯è·å–æ–‡çŒ®æ•°é‡ï¼š{keyword_strategy['estimated_papers']}ç¯‡\n\n"
            response += "æ‚¨è§‰å¾—è¿™ä¸ªç­–ç•¥åˆé€‚å—ï¼Ÿæˆ‘ä»¬å¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´ã€‚"
            
            return InteractionResponse(
                response=response,
                suggestions=analysis["suggested_refinements"],
                next_actions=[
                    {"action": "confirm_strategy", "label": "ç¡®è®¤æœç´¢ç­–ç•¥"},
                    {"action": "refine_keywords", "label": "è°ƒæ•´å…³é”®è¯"},
                    {"action": "upload_documents", "label": "ä¸Šä¼ å‚è€ƒæ–‡æ¡£"}
                ],
                requires_confirmation=True,
                estimated_time=30,
                confidence_score=analysis["confidence"]
            )
        
        return InteractionResponse(
            response="è¯·æä¾›æ›´å…·ä½“çš„ç ”ç©¶ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨åˆ¶å®šåˆé€‚çš„æ–‡çŒ®æœç´¢ç­–ç•¥ã€‚",
            confidence_score=0.3
        )
    
    async def _handle_literature_collection(self, request: InteractionRequest, session: Dict) -> InteractionResponse:
        """å¤„ç†æ–‡çŒ®é‡‡é›†é˜¶æ®µ"""
        
        if "confirm_collection" in request.message.lower():
            # é¢„æµ‹é‡‡é›†ç»“æœ
            keywords = session["context"].get("keywords", ["default"])
            prediction = await self.quality_assessor.predict_collection_outcome(keywords)
            
            response = f"æ–‡çŒ®é‡‡é›†é¢„æµ‹ç»“æœï¼š\n\n"
            response += f"â€¢ é¢„è®¡æ€»æ–‡çŒ®æ•°ï¼š{prediction['estimated_total']}ç¯‡\n"
            response += f"â€¢ é¢„è®¡ç›¸å…³æ–‡çŒ®ï¼š{prediction['estimated_relevant']}ç¯‡\n"
            response += f"â€¢ é¢„è®¡é«˜è´¨é‡æ–‡çŒ®ï¼š{prediction['estimated_high_quality']}ç¯‡\n"
            response += f"â€¢ é¢„è®¡é‡‡é›†æ—¶é—´ï¼š{prediction['estimated_time_minutes']}åˆ†é’Ÿ\n\n"
            
            if prediction['potential_issues']:
                response += "æ½œåœ¨é—®é¢˜æé†’ï¼š\n"
                for issue in prediction['potential_issues']:
                    response += f"â€¢ {issue}\n"
            
            return InteractionResponse(
                response=response,
                next_actions=[
                    {"action": "start_collection", "label": "å¼€å§‹é‡‡é›†"},
                    {"action": "adjust_strategy", "label": "è°ƒæ•´ç­–ç•¥"}
                ],
                estimated_time=prediction['estimated_time_minutes'],
                confidence_score=prediction['confidence']
            )
        
        # æ¨¡æ‹Ÿæ–‡çŒ®è´¨é‡è¯„ä¼°
        mock_literature = [{"title": f"Paper {i}", "citations": i*10} for i in range(100)]
        quality_assessment = await self.quality_assessor.assess_literature_quality(mock_literature)
        
        response = f"æ–‡çŒ®è´¨é‡è¯„ä¼°å®Œæˆï¼š\n\n"
        response += f"â€¢ æ€»æ–‡çŒ®æ•°ï¼š{quality_assessment['total_papers']}ç¯‡\n"
        response += f"â€¢ é«˜è´¨é‡æ–‡çŒ®ï¼š{quality_assessment['quality_distribution']['high']}ç¯‡\n"
        response += f"â€¢ ä¸­ç­‰è´¨é‡æ–‡çŒ®ï¼š{quality_assessment['quality_distribution']['medium']}ç¯‡\n"
        response += f"â€¢ å¹³å‡å¼•ç”¨æ¬¡æ•°ï¼š{quality_assessment['average_citation']}\n\n"
        response += f"å»ºè®®ï¼š{quality_assessment['recommendation']}"
        
        return InteractionResponse(
            response=response,
            next_actions=[
                {"action": "proceed_structuring", "label": "è¿›å…¥ç»“æ„åŒ–å¤„ç†"},
                {"action": "adjust_filters", "label": "è°ƒæ•´ç­›é€‰æ¡ä»¶"}
            ],
            confidence_score=0.85
        )
    
    async def _handle_structuring(self, request: InteractionRequest, session: Dict) -> InteractionResponse:
        """å¤„ç†è½»ç»“æ„åŒ–é˜¶æ®µ"""
        
        domain = session["context"].get("domain", "ææ–™ç§‘å­¦")
        mock_papers = [{"title": "Sample paper", "abstract": "Sample abstract"}]
        
        # ç”Ÿæˆç»“æ„åŒ–æ¨¡æ¿
        template = await self.format_optimizer.generate_structure_template(domain, mock_papers)
        
        response = f"ä¸ºæ‚¨ç”Ÿæˆäº†é€‚åˆ{domain}é¢†åŸŸçš„ç»“æ„åŒ–æ¨¡æ¿ï¼š\n\n"
        for category, subcategories in template["template_structure"].items():
            response += f"ğŸ“ {category}\n"
            for sub in subcategories:
                response += f"  â””â”€ {sub}\n"
        
        response += f"\né€‚é…ç½®ä¿¡åº¦ï¼š{template['adaptation_confidence']:.0%}\n"
        response += f"é¢„ä¼°å¤„ç†æ—¶é—´ï¼š{template['estimated_extraction_time']}åˆ†é’Ÿ"
        
        return InteractionResponse(
            response=response,
            suggestions=template["customization_suggestions"],
            next_actions=[
                {"action": "confirm_template", "label": "ç¡®è®¤æ¨¡æ¿"},
                {"action": "customize_template", "label": "è‡ªå®šä¹‰è°ƒæ•´"},
                {"action": "preview_extraction", "label": "é¢„è§ˆæå–æ•ˆæœ"}
            ],
            estimated_time=template["estimated_extraction_time"],
            confidence_score=template["adaptation_confidence"]
        )
    
    async def _handle_enhancement(self, request: InteractionRequest, session: Dict) -> InteractionResponse:
        """å¤„ç†ç»éªŒå¢å¼ºé˜¶æ®µ"""
        
        current_round = session["context"].get("enhancement_round", 1)
        mock_iteration_data = {
            "current_round": current_round,
            "content_size": 1000 + current_round * 200
        }
        
        quality_monitor = await self.enhancement_monitor.monitor_iteration_quality(mock_iteration_data)
        
        response = f"ç»éªŒå¢å¼ºè¿­ä»£ç›‘æ§ - ç¬¬{current_round}è½®ï¼š\n\n"
        response += f"â€¢ å½“å‰è´¨é‡è¯„åˆ†ï¼š{quality_monitor['quality_score']:.0%}\n"
        response += f"â€¢ å†…å®¹å¢é•¿ç‡ï¼š{quality_monitor['content_growth_rate']:.0%}\n"
        response += f"â€¢ é¢„è®¡å‰©ä½™è½®æ¬¡ï¼š{quality_monitor['estimated_remaining_rounds']}è½®\n\n"
        
        if quality_monitor['stop_recommendation']:
            response += "ğŸ¯ å»ºè®®åœæ­¢è¿­ä»£ï¼šå¢é‡æ”¶ç›Šå·²ä½äºé˜ˆå€¼\n"
            
            # é¢„æµ‹æœ€ç»ˆè´¨é‡
            final_prediction = await self.enhancement_monitor.predict_final_quality(mock_iteration_data)
            response += f"\næœ€ç»ˆè´¨é‡é¢„æµ‹ï¼š{final_prediction['predicted_final_score']:.0%}"
            
            return InteractionResponse(
                response=response,
                next_actions=[
                    {"action": "stop_iteration", "label": "åœæ­¢è¿­ä»£"},
                    {"action": "continue_iteration", "label": "ç»§ç»­1è½®"},
                    {"action": "view_experience_book", "label": "æŸ¥çœ‹ç»éªŒä¹¦"}
                ],
                confidence_score=0.9
            )
        else:
            if quality_monitor['improvement_areas']:
                response += "æ”¹è¿›å»ºè®®ï¼š\n"
                for area in quality_monitor['improvement_areas']:
                    response += f"â€¢ {area}\n"
            
            return InteractionResponse(
                response=response,
                next_actions=[
                    {"action": "continue_iteration", "label": "ç»§ç»­ä¸‹ä¸€è½®"},
                    {"action": "view_current_progress", "label": "æŸ¥çœ‹å½“å‰è¿›åº¦"}
                ],
                estimated_time=15,
                confidence_score=quality_monitor['quality_score']
            )
    
    async def _handle_solution_generation(self, request: InteractionRequest, session: Dict) -> InteractionResponse:
        """å¤„ç†æ–¹æ¡ˆç”Ÿæˆé˜¶æ®µ"""
        
        user_question = request.message
        
        response = f"åŸºäºæ‚¨çš„é—®é¢˜ï¼šã€Œ{user_question}ã€\n\n"
        response += "æˆ‘å·²ä»ç»éªŒåº“ä¸­æ£€ç´¢åˆ°ç›¸å…³ä¿¡æ¯ï¼Œæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆè§£å†³æ–¹æ¡ˆ...\n\n"
        response += "ğŸ’¡ è§£å†³æ–¹æ¡ˆå»ºè®®ï¼š\n"
        response += "1. ä¼˜åŒ–åˆ¶å¤‡å·¥è‰ºå‚æ•°ï¼ˆæ¸©åº¦ã€æ—¶é—´ã€å‹åŠ›ï¼‰\n"
        response += "2. æ”¹è¿›åŸæ–™é¢„å¤„ç†æ–¹æ³•\n"
        response += "3. å¼•å…¥æ–°å‹æ·»åŠ å‰‚æˆ–å‚¬åŒ–å‰‚\n\n"
        response += "ğŸ“Š å¯è¡Œæ€§è¯„ä¼°ï¼šé«˜ï¼ˆ85%ï¼‰\n"
        response += "â±ï¸ é¢„è®¡å®éªŒå‘¨æœŸï¼š2-3å‘¨\n"
        response += "ğŸ’° é¢„ä¼°æˆæœ¬ï¼šä¸­ç­‰"
        
        return InteractionResponse(
            response=response,
            suggestions=[
                "éœ€è¦æ›´è¯¦ç»†çš„å®éªŒæ–¹æ¡ˆå—ï¼Ÿ",
                "è¦æŸ¥çœ‹ç›¸å…³æ–‡çŒ®æ”¯æ’‘å—ï¼Ÿ",
                "éœ€è¦é£é™©è¯„ä¼°æŠ¥å‘Šå—ï¼Ÿ"
            ],
            next_actions=[
                {"action": "detailed_protocol", "label": "è·å–è¯¦ç»†å®éªŒæ–¹æ¡ˆ"},
                {"action": "view_references", "label": "æŸ¥çœ‹å‚è€ƒæ–‡çŒ®"},
                {"action": "risk_assessment", "label": "é£é™©è¯„ä¼°"},
                {"action": "export_report", "label": "å¯¼å‡ºå®Œæ•´æŠ¥å‘Š"}
            ],
            confidence_score=0.85
        )
    
    async def get_session_status(self, session_id: str) -> Dict[str, Any]:
        """è·å–ä¼šè¯çŠ¶æ€"""
        if session_id not in self.user_sessions:
            return {"error": "Session not found"}
        
        session = self.user_sessions[session_id]
        return {
            "session_id": session_id,
            "start_time": session["start_time"].isoformat(),
            "current_stage": session.get("current_stage"),
            "user_level": session["user_level"].value,
            "progress": session.get("progress", 0),
            "context_keys": list(session["context"].keys())
        }


# å…¨å±€AIåŠ©æ‰‹å®ä¾‹
ai_assistant = LiteratureAIAssistant()