"""
é«˜æ€§èƒ½æ–‡çŒ®å¤„ç†ç®¡é“ - æ”¯æŒå¤šç§PDFå¤„ç†æ–¹å¼å’Œå¹¶å‘æ¶æ„
"""

import asyncio
import time
import hashlib
from typing import List, Dict, Optional, Tuple, Union
from enum import Enum
from dataclasses import dataclass
from pathlib import Path
import aiofiles
import aiohttp
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import PyPDF2
import pdfplumber
from sqlalchemy.orm import Session

from app.core.database import get_db
from app.models.shared_literature import SharedLiterature, LiteratureProcessingTask
from app.services.research_rabbit_client import ResearchRabbitClient
from app.services.pdf_processor import PDFProcessor
from app.core.config import settings

class ProcessingMethod(Enum):
    """PDFå¤„ç†æ–¹å¼"""
    FAST_BASIC = "fast_basic"           # å¿«é€ŸåŸºç¡€è§£æ (PyPDF2) - 1-2ç§’
    STANDARD = "standard"               # æ ‡å‡†è§£æ (pdfplumber) - 3-5ç§’  
    PREMIUM_MINERU = "premium_mineru"   # é«˜è´¨é‡è§£æ (MinerU) - 30-60ç§’
    
class ProcessingStatus(Enum):
    """å¤„ç†çŠ¶æ€"""
    PENDING = "pending"
    SEARCHING = "searching" 
    DOWNLOADING = "downloading"
    PROCESSING_FAST = "processing_fast"
    PROCESSING_STANDARD = "processing_standard"
    PROCESSING_PREMIUM = "processing_premium"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class ProcessingTask:
    """å¤„ç†ä»»åŠ¡"""
    task_id: str
    paper_id: str
    title: str
    pdf_url: str
    doi: Optional[str] = None
    method: ProcessingMethod
    priority: int = 5
    created_at: float = None

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()

class LiteratureProcessingPipeline:
    """é«˜æ€§èƒ½æ–‡çŒ®å¤„ç†ç®¡é“"""
    
    def __init__(self):
        self.research_rabbit = ResearchRabbitClient()
        self.pdf_processor = PDFProcessor()
        
        # å¹¶å‘æ§åˆ¶
        self.max_concurrent_downloads = 10
        self.max_concurrent_processing = 5
        self.download_semaphore = asyncio.Semaphore(self.max_concurrent_downloads)
        self.processing_semaphore = asyncio.Semaphore(self.max_concurrent_processing)
        
        # ä»»åŠ¡é˜Ÿåˆ—
        self.download_queue = asyncio.Queue()
        self.processing_queue = asyncio.Queue()
        
        # çº¿ç¨‹æ± æ‰§è¡Œå™¨
        self.thread_executor = ThreadPoolExecutor(max_workers=8)
        self.process_executor = ProcessPoolExecutor(max_workers=4)
        
        # çŠ¶æ€è·Ÿè¸ª
        self.task_status: Dict[str, ProcessingStatus] = {}
        self.task_results: Dict[str, Dict] = {}
        self.task_progress: Dict[str, float] = {}
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        self._start_workers()
    
    def _start_workers(self):
        """å¯åŠ¨åå°å·¥ä½œçº¿ç¨‹"""
        # ä¸‹è½½å·¥ä½œçº¿ç¨‹
        for i in range(3):
            asyncio.create_task(self._download_worker(f"downloader-{i}"))
        
        # å¤„ç†å·¥ä½œçº¿ç¨‹  
        for i in range(2):
            asyncio.create_task(self._processing_worker(f"processor-{i}"))
    
    async def batch_search_and_process(
        self, 
        query: str, 
        max_results: int = 20,
        preferred_method: ProcessingMethod = ProcessingMethod.FAST_BASIC,
        user_choice_callback = None
    ) -> Dict:
        """æ‰¹é‡æœç´¢å’Œå¤„ç†æ–‡çŒ®"""
        
        start_time = time.time()
        
        # 1. å¹¶å‘æœç´¢
        print(f"ğŸ” å¼€å§‹æœç´¢: {query}")
        self.task_status["search"] = ProcessingStatus.SEARCHING
        
        papers = await self.research_rabbit.search_all_papers(
            query=query,
            max_count=max_results
        )

        if not papers:
            return {"error": "æœç´¢æ— ç»“æœ", "papers": []}

        print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(papers)} ç¯‡æ–‡çŒ®")
        
        # 2. åˆ›å»ºå¤„ç†ä»»åŠ¡
        tasks = []
        for i, paper in enumerate(papers):
            external_ids = paper.get("externalIds", {}) if isinstance(paper.get("externalIds"), dict) else {}
            task = ProcessingTask(
                task_id=f"task_{int(time.time())}_{i}",
                paper_id=paper.get("paperId") or paper.get("id", f"paper_{i}"),
                title=paper.get("title", "Unknown"),
                pdf_url=paper.get("pdfUrl") or paper.get("pdf_url", ""),
                doi=external_ids.get("DOI"),
                method=preferred_method,
                priority=5 - (i // 5)  # å‰å‡ ä¸ªä¼˜å…ˆçº§é«˜
            )
            tasks.append(task)
            self.task_status[task.task_id] = ProcessingStatus.PENDING
            self.task_progress[task.task_id] = 0.0
        
        # 3. å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        print(f"âš¡ å¼€å§‹å¹¶å‘å¤„ç† {len(tasks)} ä¸ªä»»åŠ¡...")
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡ç»„
        processing_tasks = [
            asyncio.create_task(self._process_single_paper(task))
            for task in tasks
        ]
        
        # å¦‚æœæä¾›äº†ç”¨æˆ·é€‰æ‹©å›è°ƒï¼Œå¯åŠ¨äº¤äº’å¼å¤„ç†
        if user_choice_callback:
            asyncio.create_task(self._handle_user_choices(tasks, user_choice_callback))
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆæˆ–è¶…æ—¶
        try:
            results = await asyncio.wait_for(
                asyncio.gather(*processing_tasks, return_exceptions=True),
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
        except asyncio.TimeoutError:
            print("âš ï¸ éƒ¨åˆ†ä»»åŠ¡è¶…æ—¶ï¼Œè¿”å›å·²å®Œæˆçš„ç»“æœ")
            results = [self.task_results.get(task.task_id, {"error": "timeout"}) for task in tasks]
        
        # 4. æ±‡æ€»ç»“æœ
        end_time = time.time()
        total_time = end_time - start_time
        
        successful_results = [r for r in results if isinstance(r, dict) and r.get("success")]
        failed_results = [r for r in results if not (isinstance(r, dict) and r.get("success"))]
        
        return {
            "success": True,
            "summary": {
                "total_papers": len(papers),
                "successful": len(successful_results),
                "failed": len(failed_results),
                "total_time": f"{total_time:.2f}s",
                "avg_time_per_paper": f"{total_time/len(papers):.2f}s"
            },
            "results": successful_results,
            "failed": failed_results,
            "processing_methods_used": {
                "fast": len([r for r in successful_results if r.get("method") == "fast_basic"]),
                "standard": len([r for r in successful_results if r.get("method") == "standard"]),
                "premium": len([r for r in successful_results if r.get("method") == "premium_mineru"])
            }
        }
    
    async def _process_single_paper(self, task: ProcessingTask) -> Dict:
        """å¤„ç†å•ç¯‡æ–‡çŒ®"""
        try:
            # 1. ä¸‹è½½PDF
            pdf_url = task.pdf_url
            if not pdf_url and task.doi:
                pdf_info = await self.research_rabbit.get_pdf_info(task.doi)
                if pdf_info:
                    pdf_url = pdf_info.get("url_for_pdf") or pdf_info.get("pdf_url")

            if not pdf_url:
                return {"error": "æ— å¯ç”¨PDFé“¾æ¥", "task_id": task.task_id, "title": task.title}

            self.task_status[task.task_id] = ProcessingStatus.DOWNLOADING
            self.task_progress[task.task_id] = 0.1
            
            pdf_content = await self._download_pdf_with_retry(pdf_url)
            if not pdf_content:
                return {"error": "PDFä¸‹è½½å¤±è´¥", "task_id": task.task_id}
            
            self.task_progress[task.task_id] = 0.3
            
            # 2. æ ¹æ®æ–¹æ³•é€‰æ‹©å¤„ç†æ–¹å¼
            if task.method == ProcessingMethod.FAST_BASIC:
                result = await self._process_pdf_fast(pdf_content, task)
            elif task.method == ProcessingMethod.STANDARD:
                result = await self._process_pdf_standard(pdf_content, task)
            elif task.method == ProcessingMethod.PREMIUM_MINERU:
                result = await self._process_pdf_premium(pdf_content, task)
            else:
                # é»˜è®¤å¿«é€Ÿå¤„ç†
                result = await self._process_pdf_fast(pdf_content, task)
            
            # 3. ä¿å­˜ç»“æœ
            self.task_status[task.task_id] = ProcessingStatus.COMPLETED
            self.task_progress[task.task_id] = 1.0
            self.task_results[task.task_id] = result
            
            return result
            
        except Exception as e:
            error_result = {
                "error": str(e),
                "task_id": task.task_id,
                "title": task.title,
                "success": False
            }
            self.task_status[task.task_id] = ProcessingStatus.FAILED
            self.task_results[task.task_id] = error_result
            return error_result
    
    async def _download_pdf_with_retry(self, pdf_url: str, max_retries: int = 3) -> Optional[bytes]:
        """å¸¦é‡è¯•çš„PDFä¸‹è½½"""
        async with self.download_semaphore:
            for attempt in range(max_retries):
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.get(pdf_url, timeout=30) as response:
                            if response.status == 200:
                                return await response.read()
                except Exception as e:
                    if attempt == max_retries - 1:
                        print(f"âŒ PDFä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                        return None
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            return None
    
    async def _process_pdf_fast(self, pdf_content: bytes, task: ProcessingTask) -> Dict:
        """å¿«é€ŸPDFå¤„ç† (PyPDF2) - 1-2ç§’"""
        self.task_status[task.task_id] = ProcessingStatus.PROCESSING_FAST
        self.task_progress[task.task_id] = 0.5
        
        start_time = time.time()
        
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒCPUå¯†é›†å‹æ“ä½œ
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.thread_executor,
            self._extract_text_pypdf2,
            pdf_content
        )
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "task_id": task.task_id,
            "title": task.title,
            "method": "fast_basic",
            "processing_time": f"{processing_time:.2f}s",
            "content": result.get("text", ""),
            "metadata": result.get("metadata", {}),
            "quality_score": 60,  # å¿«é€Ÿå¤„ç†è´¨é‡è¾ƒä½
            "features": ["åŸºç¡€æ–‡æœ¬æå–", "å¿«é€Ÿå¤„ç†"]
        }
    
    async def _process_pdf_standard(self, pdf_content: bytes, task: ProcessingTask) -> Dict:
        """æ ‡å‡†PDFå¤„ç† (pdfplumber) - 3-5ç§’"""
        self.task_status[task.task_id] = ProcessingStatus.PROCESSING_STANDARD
        self.task_progress[task.task_id] = 0.5
        
        start_time = time.time()
        
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒCPUå¯†é›†å‹æ“ä½œ
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            self.thread_executor,
            self._extract_text_pdfplumber,
            pdf_content
        )
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "task_id": task.task_id,
            "title": task.title,
            "method": "standard",
            "processing_time": f"{processing_time:.2f}s",
            "content": result.get("text", ""),
            "metadata": result.get("metadata", {}),
            "tables": result.get("tables", []),
            "quality_score": 80,  # æ ‡å‡†è´¨é‡
            "features": ["æ–‡æœ¬æå–", "è¡¨æ ¼è¯†åˆ«", "å¸ƒå±€ä¿æŒ"]
        }
    
    async def _process_pdf_premium(self, pdf_content: bytes, task: ProcessingTask) -> Dict:
        """é«˜è´¨é‡PDFå¤„ç† (MinerU) - 30-60ç§’"""
        self.task_status[task.task_id] = ProcessingStatus.PROCESSING_PREMIUM
        self.task_progress[task.task_id] = 0.5
        
        start_time = time.time()
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = f"/tmp/temp_pdf_{task.task_id}.pdf"
        async with aiofiles.open(temp_path, 'wb') as f:
            await f.write(pdf_content)
        
        # ä½¿ç”¨ç°æœ‰çš„MinerUå¤„ç†å™¨
        result = await self.pdf_processor.process_pdf(temp_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(temp_path).unlink(missing_ok=True)
        
        processing_time = time.time() - start_time
        
        if result.get("success"):
            return {
                "success": True,
                "task_id": task.task_id,
                "title": task.title,
                "method": "premium_mineru",
                "processing_time": f"{processing_time:.2f}s",
                "content": result.get("content", {}),
                "metadata": result.get("metadata", {}),
                "quality_score": 95,  # æœ€é«˜è´¨é‡
                "features": ["é«˜è´¨é‡OCR", "å®Œæ•´ç»“æ„è¯†åˆ«", "å…¬å¼æå–", "å›¾è¡¨åˆ†æ", "Markdownè¾“å‡º"]
            }
        else:
            # MinerUå¤±è´¥æ—¶é™çº§åˆ°æ ‡å‡†å¤„ç†
            return await self._process_pdf_standard(pdf_content, task)
    
    def _extract_text_pypdf2(self, pdf_content: bytes) -> Dict:
        """PyPDF2æ–‡æœ¬æå– (åŒæ­¥å‡½æ•°)"""
        try:
            import io
            from PyPDF2 import PdfReader
            
            pdf_file = io.BytesIO(pdf_content)
            reader = PdfReader(pdf_file)
            
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
            
            return {
                "text": text,
                "metadata": {
                    "pages": len(reader.pages),
                    "method": "PyPDF2"
                }
            }
        except Exception as e:
            return {"text": "", "metadata": {"error": str(e)}}
    
    def _extract_text_pdfplumber(self, pdf_content: bytes) -> Dict:
        """pdfplumberæ–‡æœ¬æå– (åŒæ­¥å‡½æ•°)"""
        try:
            import io
            import pdfplumber
            
            pdf_file = io.BytesIO(pdf_content)
            text = ""
            tables = []
            
            with pdfplumber.open(pdf_file) as pdf:
                for page in pdf.pages:
                    # æå–æ–‡æœ¬
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                    
                    # æå–è¡¨æ ¼
                    page_tables = page.extract_tables()
                    if page_tables:
                        tables.extend(page_tables)
            
            return {
                "text": text,
                "tables": tables,
                "metadata": {
                    "pages": len(pdf.pages),
                    "method": "pdfplumber",
                    "tables_found": len(tables)
                }
            }
        except Exception as e:
            return {"text": "", "tables": [], "metadata": {"error": str(e)}}
    
    async def _handle_user_choices(self, tasks: List[ProcessingTask], callback):
        """å¤„ç†ç”¨æˆ·å®æ—¶é€‰æ‹©"""
        for task in tasks:
            # ç­‰å¾…å¿«é€Ÿå¤„ç†å®Œæˆ
            while self.task_status.get(task.task_id) != ProcessingStatus.COMPLETED:
                if self.task_status.get(task.task_id) == ProcessingStatus.PROCESSING_FAST:
                    # å¿«é€Ÿå¤„ç†å®Œæˆï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦å‡çº§
                    if task.task_id in self.task_results:
                        fast_result = self.task_results[task.task_id]
                        user_choice = await callback({
                            "task_id": task.task_id,
                            "title": task.title,
                            "fast_result_preview": fast_result.get("content", "")[:500],
                            "options": {
                                "keep_fast": "ä¿æŒå¿«é€Ÿç»“æœ (å·²å®Œæˆ)",
                                "upgrade_standard": "å‡çº§åˆ°æ ‡å‡†å¤„ç† (+3-5ç§’, æ›´å¥½è´¨é‡)",
                                "upgrade_premium": "å‡çº§åˆ°é«˜è´¨é‡å¤„ç† (+30-60ç§’, æœ€ä½³è´¨é‡)"
                            }
                        })
                        
                        if user_choice in ["upgrade_standard", "upgrade_premium"]:
                            # é‡æ–°å¤„ç†
                            new_method = ProcessingMethod.STANDARD if user_choice == "upgrade_standard" else ProcessingMethod.PREMIUM_MINERU
                            task.method = new_method
                            asyncio.create_task(self._reprocess_with_method(task, new_method))
                
                await asyncio.sleep(0.5)
    
    async def _reprocess_with_method(self, task: ProcessingTask, method: ProcessingMethod):
        """ä½¿ç”¨æ–°æ–¹æ³•é‡æ–°å¤„ç†"""
        # è¿™é‡Œå¯ä»¥é‡æ–°å¤„ç†å·²ä¸‹è½½çš„PDF
        pass
    
    async def get_processing_status(self, task_ids: List[str] = None) -> Dict:
        """è·å–å¤„ç†çŠ¶æ€"""
        if task_ids is None:
            task_ids = list(self.task_status.keys())
        
        return {
            task_id: {
                "status": self.task_status.get(task_id, "unknown").value,
                "progress": self.task_progress.get(task_id, 0.0),
                "result": self.task_results.get(task_id)
            }
            for task_id in task_ids
        }
    
    async def _download_worker(self, worker_name: str):
        """ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–ä¸‹è½½ä»»åŠ¡
                task = await self.download_queue.get()
                if task is None:  # åœæ­¢ä¿¡å·
                    break
                
                # æ‰§è¡Œä¸‹è½½
                await self._process_single_paper(task)
                self.download_queue.task_done()
                
            except Exception as e:
                print(f"âŒ ä¸‹è½½å·¥ä½œçº¿ç¨‹ {worker_name} é”™è¯¯: {e}")
                await asyncio.sleep(1)
    
    async def _processing_worker(self, worker_name: str):
        """å¤„ç†å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                # ä»é˜Ÿåˆ—è·å–å¤„ç†ä»»åŠ¡
                task = await self.processing_queue.get()
                if task is None:  # åœæ­¢ä¿¡å·
                    break
                
                # æ‰§è¡Œå¤„ç†
                # è¿™é‡Œå¯ä»¥æ·»åŠ é¢å¤–çš„å¤„ç†é€»è¾‘
                self.processing_queue.task_done()
                
            except Exception as e:
                print(f"âŒ å¤„ç†å·¥ä½œçº¿ç¨‹ {worker_name} é”™è¯¯: {e}")
                await asyncio.sleep(1)

# å…¨å±€å¤„ç†ç®¡é“å®ä¾‹
pipeline = LiteratureProcessingPipeline()
