"""
ç®€åŒ–çš„ç ”ç©¶å‘ç°API - ç”¨æˆ·å¯¼å‘çš„å•ä¸€æ¥å£
æ›¿ä»£å¤æ‚çš„å¤šæ­¥éª¤APIï¼Œæä¾›ç»Ÿä¸€çš„ç ”ç©¶ä½“éªŒ
"""

from typing import Dict, List, Optional
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel
import asyncio
from datetime import datetime
from loguru import logger

from app.core.database import get_db
from app.core.security import get_current_active_user
from app.models.user import User
from app.models.project import Project
from app.models.task import Task
from app.models.literature import Literature
from app.services.research_ai_service import research_ai_service
from app.services.research_rabbit_client import ResearchRabbitClient
from app.services.stream_progress_service import StreamProgressService

router = APIRouter()

class ResearchDiscoveryRequest(BaseModel):
    project_id: int
    query: str
    max_results: int = 50
    quality_filter: str = "high"  # high, medium, all
    time_range: str = "all"  # recent, all

class ResearchDiscoveryResponse(BaseModel):
    success: bool
    task_id: int
    message: str
    estimated_duration: int  # ç§’

@router.post("/research-discovery", response_model=ResearchDiscoveryResponse)
async def start_research_discovery(
    request: ResearchDiscoveryRequest,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """
    å¯åŠ¨æ™ºèƒ½ç ”ç©¶å‘ç° - ä¸€ä½“åŒ–æµç¨‹
    è‡ªåŠ¨å®Œæˆ: æœç´¢ â†’ ç­›é€‰ â†’ åˆ†æ â†’ æ´å¯Ÿç”Ÿæˆ
    """
    
    # éªŒè¯é¡¹ç›®æƒé™
    project = db.query(Project).filter(
        Project.id == request.project_id,
        Project.owner_id == current_user.id
    ).first()
    
    if not project:
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒé™")
    
    # åˆ›å»ºä»»åŠ¡è®°å½•
    task = Task(
        project_id=request.project_id,
        task_type="research_discovery",
        title=f"ç ”ç©¶å‘ç°: {request.query}",
        description=f"æ™ºèƒ½æœç´¢å’Œåˆ†æç›¸å…³ç ”ç©¶",
        config={
            "query": request.query,
            "max_results": request.max_results,
            "quality_filter": request.quality_filter,
            "time_range": request.time_range,
            "workflow": "integrated"  # æ ‡è®°ä¸ºä¸€ä½“åŒ–æµç¨‹
        },
        status="pending",
        estimated_duration=300  # 5åˆ†é’Ÿé¢„ä¼°
    )
    
    db.add(task)
    db.commit()
    db.refresh(task)
    
    # å¯åŠ¨ä¸€ä½“åŒ–ç ”ç©¶å‘ç°ä»»åŠ¡
    from app.tasks.celery_tasks import research_discovery_celery
    task_result = research_discovery_celery.delay(
        task.id,
        request.query,
        request.max_results,
        request.quality_filter,
        request.time_range
    )
    
    return ResearchDiscoveryResponse(
        success=True,
        task_id=task.id,
        message=f"ç ”ç©¶å‘ç°å·²å¯åŠ¨: {request.query}",
        estimated_duration=300
    )

async def integrated_research_discovery_workflow(
    task_id: int,
    query: str,
    max_results: int,
    quality_filter: str,
    time_range: str
) -> Dict:
    """
    é›†æˆçš„ç ”ç©¶å‘ç°å·¥ä½œæµ - ç®€åŒ–ç”¨æˆ·ä½“éªŒ
    """
    db = SessionLocal()
    progress_service = StreamProgressService()
    
    try:
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task = db.query(Task).filter(Task.id == task_id).first()
        if not task:
            raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
        
        project = db.query(Project).filter(Project.id == task.project_id).first()
        if not project:
            raise ValueError("é¡¹ç›®ä¸å­˜åœ¨")
        
        # é˜¶æ®µ1: æœç´¢é˜¶æ®µ (0-40%)
        task.status = "running"
        task.started_at = datetime.utcnow()
        task.current_step = "ğŸ” æ­£åœ¨æœç´¢ç›¸å…³ç ”ç©¶..."
        task.progress_percentage = 5
        db.commit()
        
        await progress_service.broadcast_task_update(task_id, {
            "type": "progress_event",
            "stage": "searching",
            "progress": 5,
            "message": "æ­£åœ¨æœç´¢ç›¸å…³ç ”ç©¶...",
            "discoveries": []
        })
        
        # ä½¿ç”¨Research Rabbitæœç´¢æ–‡çŒ®
        papers_found = []
        async with ResearchRabbitClient() as client:
            papers = await client.search_all_papers(query, max_results)
            
            # è¿›åº¦æ›´æ–°: æœç´¢å®Œæˆ
            await progress_service.broadcast_task_update(task_id, {
                "type": "progress_event",
                "stage": "searching", 
                "progress": 25,
                "message": f"å‘ç° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡",
                "discoveries": [{
                    "type": "paper",
                    "title": "æ–‡çŒ®æœç´¢",
                    "description": f"ä»å­¦æœ¯æ•°æ®åº“ä¸­æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³ç ”ç©¶è®ºæ–‡",
                    "confidence": 0.9,
                    "timestamp": datetime.utcnow().isoformat()
                }]
            })
            
            # é˜¶æ®µ2: æ™ºèƒ½ç­›é€‰å’Œè´¨é‡è¯„ä¼° (25-60%)
            task.current_step = "ğŸ§  æ­£åœ¨åˆ†æè®ºæ–‡è´¨é‡..."
            task.progress_percentage = 30
            db.commit()
            
            high_quality_papers = []
            quality_discoveries = []
            
            for i, paper in enumerate(papers):
                try:
                    # ä½¿ç”¨ç»Ÿä¸€AIæœåŠ¡è¯„ä¼°è´¨é‡
                    quality_result = await research_ai_service.evaluate_literature_quality(
                        title=paper.get("title", ""),
                        abstract=paper.get("abstract", ""),
                        authors=paper.get("authors", []),
                        journal=paper.get("journal", {}).get("name", ""),
                        year=paper.get("year")
                    )
                    
                    if quality_result.get("success") and quality_result.get("overall_score", 0) > 0.6:
                        high_quality_papers.append({
                            **paper,
                            "ai_quality_score": quality_result.get("overall_score"),
                            "relevance_score": quality_result.get("relevance_score"),
                            "key_contributions": quality_result.get("key_contributions", [])
                        })
                        
                        # è®°å½•é«˜è´¨é‡å‘ç°
                        if quality_result.get("overall_score", 0) > 0.8:
                            quality_discoveries.append({
                                "type": "insight",
                                "title": f"é«˜è´¨é‡ç ”ç©¶å‘ç°",
                                "description": f"å‘ç°é«˜å½±å“åŠ›è®ºæ–‡: {paper.get('title', '')[:100]}",
                                "confidence": quality_result.get("overall_score"),
                                "timestamp": datetime.utcnow().isoformat()
                            })
                    
                    # æ›´æ–°è¿›åº¦
                    if (i + 1) % 5 == 0:
                        progress = 30 + int((i + 1) / len(papers) * 30)
                        await progress_service.broadcast_task_update(task_id, {
                            "type": "progress_event",
                            "stage": "analyzing",
                            "progress": progress,
                            "message": f"å·²åˆ†æ {i + 1}/{len(papers)} ç¯‡è®ºæ–‡",
                            "discoveries": quality_discoveries[-3:] if quality_discoveries else []
                        })
                        
                except Exception as e:
                    logger.warning(f"è´¨é‡è¯„ä¼°å¤±è´¥ {i}: {e}")
                    continue
            
            # é˜¶æ®µ3: ç”Ÿæˆç ”ç©¶æ´å¯Ÿ (60-90%)
            task.current_step = "âœ¨ æ­£åœ¨ç”Ÿæˆç ”ç©¶æ´å¯Ÿ..."
            task.progress_percentage = 65
            db.commit()
            
            # å‡†å¤‡æ–‡çŒ®å†…å®¹ç”¨äºæ´å¯Ÿç”Ÿæˆ
            literature_contents = []
            for paper in high_quality_papers[:10]:  # é€‰æ‹©å‰10ç¯‡é«˜è´¨é‡è®ºæ–‡
                literature_contents.append({
                    "title": paper.get("title", ""),
                    "content": paper.get("abstract", ""),
                    "quality_score": paper.get("ai_quality_score", 0),
                    "contributions": paper.get("key_contributions", [])
                })
            
            # ç”Ÿæˆç ”ç©¶æ´å¯Ÿ
            insights_result = await research_ai_service.generate_research_insights(
                query=query,
                literature_contents=literature_contents,
                focus_areas=None
            )
            
            insights_discoveries = []
            if insights_result.get("success"):
                # è½¬æ¢æ´å¯Ÿä¸ºå‘ç°æ ¼å¼
                for finding in insights_result.get("key_findings", [])[:3]:
                    insights_discoveries.append({
                        "type": "insight",
                        "title": finding.get("finding", "ç ”ç©¶å‘ç°"),
                        "description": finding.get("evidence", "")[:200],
                        "confidence": finding.get("confidence", 0.8),
                        "timestamp": datetime.utcnow().isoformat()
                    })
                
                for gap in insights_result.get("research_gaps", [])[:2]:
                    insights_discoveries.append({
                        "type": "opportunity", 
                        "title": "ç ”ç©¶æœºä¼š",
                        "description": gap.get("gap", "") + " - " + gap.get("opportunity", ""),
                        "confidence": gap.get("feasibility", 0.7),
                        "timestamp": datetime.utcnow().isoformat()
                    })
            
            await progress_service.broadcast_task_update(task_id, {
                "type": "progress_event",
                "stage": "insights",
                "progress": 85,
                "message": f"ç”Ÿæˆäº† {len(insights_discoveries)} ä¸ªç ”ç©¶æ´å¯Ÿ",
                "discoveries": insights_discoveries
            })
            
            # é˜¶æ®µ4: å®Œæˆ (90-100%)
            task.status = "completed"
            task.current_step = "ç ”ç©¶å‘ç°å®Œæˆ"
            task.progress_percentage = 100
            task.completed_at = datetime.utcnow()
            task.actual_duration = int((task.completed_at - task.started_at).total_seconds())
            task.result = {
                "success": True,
                "total_papers_found": len(papers),
                "high_quality_papers": len(high_quality_papers),
                "insights_generated": len(insights_result.get("key_findings", [])),
                "research_gaps": len(insights_result.get("research_gaps", [])),
                "recommendations": insights_result.get("recommendations", []),
                "query": query
            }
            db.commit()
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            all_discoveries = quality_discoveries + insights_discoveries
            await progress_service.broadcast_task_update(task_id, {
                "type": "progress_event", 
                "stage": "complete",
                "progress": 100,
                "message": f"ç ”ç©¶å‘ç°å®Œæˆï¼æ‰¾åˆ° {len(high_quality_papers)} ç¯‡é«˜è´¨é‡è®ºæ–‡ï¼Œç”Ÿæˆ {len(all_discoveries)} ä¸ªç ”ç©¶å‘ç°",
                "discoveries": all_discoveries,
                "final_results": task.result
            })
            
            return {"success": True, "discoveries": all_discoveries}
            
    except Exception as e:
        logger.error(f"ç ”ç©¶å‘ç°å·¥ä½œæµå¤±è´¥: {e}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        task.status = "failed"
        task.error_message = str(e)
        task.completed_at = datetime.utcnow()
        db.commit()
        
        await progress_service.broadcast_task_update(task_id, {
            "type": "progress_event",
            "stage": "failed",
            "progress": 0,
            "message": f"ç ”ç©¶å‘ç°å¤±è´¥: {str(e)}",
            "error": str(e)
        })
        
        return {"success": False, "error": str(e)}
    
    finally:
        db.close()

# ç®€åŒ–çš„æ–‡çŒ®å¤„ç†çŠ¶æ€API
@router.get("/research-discovery/{task_id}/status")
async def get_research_discovery_status(
    task_id: int,
    current_user: User = Depends(get_current_active_user),
    db: Session = Depends(get_db)
):
    """è·å–ç ”ç©¶å‘ç°ä»»åŠ¡çŠ¶æ€"""
    
    task = db.query(Task).filter(
        Task.id == task_id,
        Task.task_type == "research_discovery"
    ).first()
    
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # éªŒè¯é¡¹ç›®æƒé™
    project = db.query(Project).filter(
        Project.id == task.project_id,
        Project.owner_id == current_user.id
    ).first()
    
    if not project:
        raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®æ­¤ä»»åŠ¡")
    
    return {
        "task_id": task_id,
        "status": task.status,
        "progress": task.progress_percentage,
        "current_step": task.current_step,
        "started_at": task.started_at,
        "completed_at": task.completed_at,
        "result": task.result,
        "error": task.error_message
    }