"""
æ–‡çŒ®å¤„ç†ç›¸å…³çš„åå°ä»»åŠ¡
"""

import os
from datetime import datetime
from typing import List, Dict, Any
from loguru import logger
from sqlalchemy.orm import Session

from app.core.database import SessionLocal
from app.core.config import settings
from app.models.task import Task, TaskProgress
from app.models.project import Project
from app.models.literature import Literature, LiteratureSegment
from app.models.user import User
from app.services.literature_collector import EnhancedLiteratureCollector
from app.services.pdf_processor import PDFProcessor
from app.services.research_ai_service import research_ai_service
from app.services.experience_engine import EnhancedExperienceEngine
from app.tasks.literature_tasks_helper import create_basic_segments

async def safe_broadcast_update(progress_service, task_id: int, data: dict):
    """å®‰å…¨çš„WebSocketå¹¿æ’­æ›´æ–°"""
    try:
        await progress_service.broadcast_task_update(task_id, data)
    except Exception as ws_error:
        logger.warning(f"WebSocketæ›´æ–°å¤±è´¥ (Task {task_id}): {ws_error}")

def ai_search_batch_task(
    task_id: int,
    query: str,
    max_results: int
):
    """
    AIæ‰¹é‡æœç´¢æ–‡çŒ®çš„åå°ä»»åŠ¡
    """
    import asyncio
    
    try:
        # è¿è¡Œå¼‚æ­¥æœç´¢ä»»åŠ¡
        asyncio.run(ai_search_batch_async(task_id, query, max_results))
    except Exception as e:
        logger.error(f"AIæœç´¢ä»»åŠ¡å¤±è´¥: {e}")
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        db = SessionLocal()
        try:
            task = db.query(Task).filter(Task.id == task_id).first()
            if task:
                task.status = "failed"
                task.error_message = str(e)
                task.completed_at = datetime.utcnow()
                task.progress_percentage = 0
                db.commit()
                
                # å‘é€WebSocketæ›´æ–°
                from app.services.stream_progress_service import StreamProgressService
                progress_service = StreamProgressService()
                # Note: Cannot await in sync function, WebSocket update will be handled by async task
        finally:
            db.close()

async def ai_search_batch_async(
    task_id: int,
    query: str,
    max_results: int
):
    """
    å¼‚æ­¥AIæœç´¢ä»»åŠ¡å®ç°
    """
    db = SessionLocal()
    
    try:
        # è·å–ä»»åŠ¡ä¿¡æ¯
        task = db.query(Task).filter(Task.id == task_id).first()
        if not task:
            raise ValueError("ä»»åŠ¡ä¸å­˜åœ¨")
            
        project = db.query(Project).filter(Project.id == task.project_id).first()
        if not project:
            raise ValueError("é¡¹ç›®ä¸å­˜åœ¨")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task.status = "running"
        task.started_at = datetime.utcnow()
        task.progress_percentage = 0
        task.current_step = "ğŸ” æ­£åœ¨ä¸ºæ‚¨å¯»æ‰¾ç›¸å…³ç ”ç©¶æ–‡çŒ®..."
        db.commit()
        
        # å‘é€WebSocketæ›´æ–°
        from app.services.stream_progress_service import StreamProgressService
        progress_service = StreamProgressService()
        await safe_broadcast_update(progress_service, task_id, {
            "type": "task_started",
            "task_id": task_id,
            "progress": 0,
            "current_step": "ğŸ” æ­£åœ¨ä¸ºæ‚¨å¯»æ‰¾ç›¸å…³ç ”ç©¶æ–‡çŒ®..."
        })
        
        # ä½¿ç”¨Research Rabbit APIæœç´¢
        from app.services.research_rabbit_client import ResearchRabbitClient
        from app.services.shared_literature_service import SharedLiteratureService
        
        literature_service = SharedLiteratureService(db)
        total_found = 0
        total_added = 0
        
        async with ResearchRabbitClient() as client:
            # æ›´æ–°è¿›åº¦: 10%
            task.progress_percentage = 10
            task.current_step = f"ğŸ“š æ­£åœ¨æœç´¢ä¸»é¢˜ï¼š{query}"
            db.commit()
            
            await safe_broadcast_update(progress_service, task_id, {
                "type": "task_progress",
                "task_id": task_id,
                "progress": 10,
                "current_step": f"ğŸ“š æ­£åœ¨æœç´¢ä¸»é¢˜ï¼š{query}"
            })
            
            # æœç´¢æ–‡çŒ®
            papers = await client.search_all_papers(query, max_results)
            total_found = len(papers)
            
            # æ›´æ–°è¿›åº¦: 30%
            task.progress_percentage = 30
            task.current_step = f"âœ… å‘ç° {total_found} ç¯‡ç›¸å…³è®ºæ–‡ï¼Œæ­£åœ¨ä¸ºæ‚¨ç­›é€‰ä¼˜è´¨å†…å®¹..."
            db.commit()
            
            await safe_broadcast_update(progress_service, task_id, {
                "type": "task_progress", 
                "task_id": task_id,
                "progress": 30,
                "current_step": f"âœ… å‘ç° {total_found} ç¯‡ç›¸å…³è®ºæ–‡ï¼Œæ­£åœ¨ä¸ºæ‚¨ç­›é€‰ä¼˜è´¨å†…å®¹...",
                "found_count": total_found
            })
            
            # å¤„ç†æ¯ç¯‡æ–‡çŒ®
            new_papers = []
            for i, paper in enumerate(papers):
                try:
                    # å®‰å…¨åœ°è·å–å­—æ®µ
                    external_ids = paper.get("externalIds") or {}
                    if isinstance(external_ids, str):
                        external_ids = {}
                        
                    doi = external_ids.get("DOI") if isinstance(external_ids, dict) else None
                    arxiv_id = external_ids.get("ArXiv") if isinstance(external_ids, dict) else None
                    title = paper.get("title", "")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_lit = await literature_service.find_existing_literature(
                        doi=doi, arxiv_id=arxiv_id, title=title
                    )
                    
                    if existing_lit is None:
                        new_papers.append(paper)
                    
                    # æ›´æ–°è¿›åº¦
                    progress = 30 + int((i + 1) / len(papers) * 40)  # 30% to 70%
                    if (i + 1) % 5 == 0:  # æ¯5ç¯‡æ›´æ–°ä¸€æ¬¡
                        task.progress_percentage = progress
                        task.current_step = f"â³ å·²è¯„ä¼° {i + 1}/{len(papers)} ç¯‡è®ºæ–‡ (é¢„è®¡è¿˜éœ€ {((len(papers)-(i+1))*2)//60+1} åˆ†é’Ÿ)"
                        db.commit()
                        
                        await safe_broadcast_update(progress_service, task_id, {
                            "type": "task_progress",
                            "task_id": task_id,
                            "progress": progress,
                            "current_step": f"â³ å·²è¯„ä¼° {i + 1}/{len(papers)} ç¯‡è®ºæ–‡ (é¢„è®¡è¿˜éœ€ {((len(papers)-(i+1))*2)//60+1} åˆ†é’Ÿ)",
                            "processed_count": i + 1,
                            "total_count": len(papers)
                        })
                        
                except Exception as e:
                    logger.warning(f"å¤„ç†æ–‡çŒ® {i} æ—¶å‡ºé”™: {e}")
                    continue
            
            # æ·»åŠ æ–°æ–‡çŒ®
            if new_papers:
                task.progress_percentage = 70
                task.current_step = f"ğŸ“– æ­£åœ¨ä¸ºæ‚¨çš„é¡¹ç›®æ·»åŠ  {len(new_papers)} ç¯‡ä¼˜è´¨è®ºæ–‡..."
                db.commit()
                
                await safe_broadcast_update(progress_service, task_id, {
                    "type": "task_progress",
                    "task_id": task_id,
                    "progress": 70,
                    "current_step": f"ğŸ“– æ­£åœ¨ä¸ºæ‚¨çš„é¡¹ç›®æ·»åŠ  {len(new_papers)} ç¯‡ä¼˜è´¨è®ºæ–‡...",
                    "new_count": len(new_papers)
                })
                
                # æ‰¹é‡æ·»åŠ æ–‡çŒ®
                paper_ids = [paper.get("paperId", "") for paper in new_papers if paper.get("paperId")]
                if paper_ids:
                    # è·å–ç”¨æˆ·ID
                    user = db.query(User).filter(User.id == project.owner_id).first()
                    if user:
                        for paper in new_papers:
                            try:
                                await literature_service.add_literature_from_search(
                                    user_id=user.id,
                                    project_id=task.project_id,
                                    paper_data=paper
                                )
                                total_added += 1
                            except Exception as e:
                                logger.warning(f"æ·»åŠ æ–‡çŒ®å¤±è´¥: {e}")
                                continue
            
            # ä»»åŠ¡å®Œæˆ
            task.status = "completed"
            task.progress_percentage = 100
            task.current_step = "ä»»åŠ¡å®Œæˆ"
            task.completed_at = datetime.utcnow()
            task.actual_duration = int((task.completed_at - task.started_at).total_seconds())
            task.result = {
                "total_found": total_found,
                "total_added": total_added,
                "query": query,
                "success": True
            }
            db.commit()
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            await safe_broadcast_update(progress_service, task_id, {
                "type": "task_completed",
                "task_id": task_id,
                "progress": 100,
                "current_step": "ğŸ‰ æ–‡çŒ®æœç´¢å®Œæˆï¼å·²ä¸ºæ‚¨çš„é¡¹ç›®æ·»åŠ é«˜è´¨é‡ç ”ç©¶èµ„æ–™",
                "result": {
                    "total_found": total_found,
                    "total_added": total_added,
                    "query": query,
                    "message": f"æˆåŠŸæœç´¢ {total_found} ç¯‡æ–‡çŒ®ï¼Œæ·»åŠ  {total_added} ç¯‡æ–°æ–‡çŒ®"
                }
            })
            
    except Exception as e:
        # å¤„ç†å¼‚å¸¸
        logger.error(f"AIæœç´¢ä»»åŠ¡å¼‚å¸¸: {e}")
        task.status = "failed"
        task.error_message = str(e)
        task.completed_at = datetime.utcnow()
        db.commit()
        
        # å‘é€å¤±è´¥æ¶ˆæ¯
        await safe_broadcast_update(progress_service, task_id, {
            "type": "task_failed",
            "task_id": task_id,
            "error": str(e)
        })
        raise
        
    finally:
        db.close()

async def start_search_and_build_library_task(
    task_id: int,
    keywords: List[str],
    project_id: int,
    user_id: int,
    config: Dict[str, Any]
):
    """
    å¯åŠ¨æœç´¢å»ºåº“åŸå­åŒ–ä»»åŠ¡
    æ‰§è¡Œå®Œæ•´çš„æœç´¢â†’ç­›é€‰â†’ä¸‹è½½PDFâ†’è½¬Markdownâ†’ç»“æ„åŒ–å¤„ç†â†’å…¥åº“æµæ°´çº¿
    """
    db = SessionLocal()

    try:
        # è·å–ä»»åŠ¡å’Œé¡¹ç›®ä¿¡æ¯
        task = db.query(Task).filter(Task.id == task_id).first()
        if not task:
            logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return {"success": False, "error": "ä»»åŠ¡ä¸å­˜åœ¨"}

        project = db.query(Project).filter(
            Project.id == project_id,
            Project.owner_id == user_id
        ).first()
        if not project:
            logger.error(f"é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®: {project_id}")
            return {"success": False, "error": "é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"}

        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            logger.error(f"ç”¨æˆ·ä¸å­˜åœ¨: {user_id}")
            return {"success": False, "error": "ç”¨æˆ·ä¸å­˜åœ¨"}

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.status = "running"
        task.start_time = datetime.utcnow()
        task.current_step = "åˆå§‹åŒ–æœç´¢å»ºåº“æµæ°´çº¿"
        task.progress_percentage = 0
        db.commit()

        logger.info(f"å¼€å§‹æœç´¢å»ºåº“ä»»åŠ¡ {task_id}: å…³é”®è¯={keywords}, é¡¹ç›®={project_id}")

        # å‘é€WebSocketæ›´æ–°
        from app.services.stream_progress_service import StreamProgressService
        progress_service = StreamProgressService()

        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        async def progress_callback(step: str, progress: int, details: dict = None):
            try:
                task.current_step = step
                task.progress_percentage = progress
                if details:
                    task.result = details
                db.commit()

                # å‘é€WebSocketæ›´æ–°
                await safe_broadcast_update(progress_service, task_id, {
                    "type": "task_progress",
                    "task_id": task_id,
                    "progress": progress,
                    "current_step": step,
                    "details": details
                })

                logger.info(f"ä»»åŠ¡ {task_id} è¿›åº¦æ›´æ–°: {step} ({progress}%)")
            except Exception as e:
                logger.warning(f"æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")

        try:
            # ä½¿ç”¨æœç´¢å»ºåº“æœåŠ¡æ‰§è¡Œå®Œæ•´æµæ°´çº¿
            from app.services.search_and_build_library_service import (
                create_search_and_build_library_service,
                ProcessingConfig
            )

            # æ„å»ºå¤„ç†é…ç½®
            processing_config = ProcessingConfig(
                batch_size=config.get("batch_size", 10),
                max_concurrent_downloads=config.get("max_concurrent_downloads", 5),
                max_concurrent_ai_calls=3,
                enable_ai_filtering=config.get("enable_ai_filtering", True),
                enable_pdf_processing=config.get("enable_pdf_processing", True),
                enable_structured_extraction=config.get("enable_structured_extraction", True),
                quality_threshold=config.get("quality_threshold", 6.0),
                max_retries=3,
                timeout_seconds=3600  # 1å°æ—¶è¶…æ—¶
            )

            # æ‰§è¡Œæœç´¢å»ºåº“æµæ°´çº¿
            async with create_search_and_build_library_service(db) as service:
                result = await service.execute_full_pipeline(
                    keywords=keywords,
                    project=project,
                    config=processing_config,
                    progress_callback=progress_callback
                )

            # ä»»åŠ¡å®Œæˆï¼Œæ›´æ–°çŠ¶æ€
            if result.get("success"):
                task.status = "completed"
                task.end_time = datetime.utcnow()
                task.current_step = "æœç´¢å»ºåº“å®Œæˆ"
                task.progress_percentage = 100.0
                task.result = {
                    "success": True,
                    "stats": result.get("stats", {}),
                    "processed_items": result.get("processed_items", 0),
                    "processing_time": result.get("processing_time", 0)
                }

                # å‘é€å®Œæˆæ¶ˆæ¯
                await safe_broadcast_update(progress_service, task_id, {
                    "type": "task_completed",
                    "task_id": task_id,
                    "progress": 100,
                    "current_step": "æœç´¢å»ºåº“å®Œæˆ",
                    "result": task.result
                })

                logger.info(f"æœç´¢å»ºåº“ä»»åŠ¡ {task_id} å®Œæˆ: {result.get('stats', {})}")
            else:
                # ä»»åŠ¡å¤±è´¥
                task.status = "failed"
                task.end_time = datetime.utcnow()
                task.error_message = result.get("error", "æœç´¢å»ºåº“å¤±è´¥")
                task.result = {"success": False, "error": task.error_message}

                # å‘é€å¤±è´¥æ¶ˆæ¯
                await safe_broadcast_update(progress_service, task_id, {
                    "type": "task_failed",
                    "task_id": task_id,
                    "error": task.error_message
                })

            db.commit()
            return result

        except Exception as e:
            logger.error(f"æœç´¢å»ºåº“ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            task.status = "failed"
            task.end_time = datetime.utcnow()
            task.error_message = str(e)
            task.result = {"success": False, "error": str(e)}

            # å‘é€å¤±è´¥æ¶ˆæ¯
            await safe_broadcast_update(progress_service, task_id, {
                "type": "task_failed",
                "task_id": task_id,
                "error": str(e)
            })

            db.commit()
            return {"success": False, "error": str(e)}

    except Exception as e:
        logger.error(f"æœç´¢å»ºåº“ä»»åŠ¡å¼‚å¸¸: {e}")
        return {"success": False, "error": str(e)}

    finally:
        db.close()


async def start_literature_collection_task(
    task_id: int,
    keywords: List[str],
    max_count: int,
    sources: List[str]
):
    """å¯åŠ¨æ–‡çŒ®é‡‡é›†ä»»åŠ¡"""
    db = SessionLocal()
    
    try:
        # è·å–ä»»åŠ¡å’Œé¡¹ç›®ä¿¡æ¯
        task = db.query(Task).filter(Task.id == task_id).first()
        if not task:
            logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return
        
        project = db.query(Project).filter(Project.id == task.project_id).first()
        if not project:
            logger.error(f"é¡¹ç›®ä¸å­˜åœ¨: {task.project_id}")
            return
        
        user = db.query(User).filter(User.id == project.owner_id).first()
        if not user:
            logger.error(f"ç”¨æˆ·ä¸å­˜åœ¨: {project.owner_id}")
            return
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task.status = "running"
        task.start_time = datetime.utcnow()
        task.current_step = "åˆå§‹åŒ–æ–‡çŒ®é‡‡é›†"
        db.commit()
        
        logger.info(f"å¼€å§‹æ–‡çŒ®é‡‡é›†ä»»åŠ¡ {task_id}: å…³é”®è¯={keywords}, æ•°é‡={max_count}")
        
        # ä½¿ç”¨å¢å¼ºçš„æ–‡çŒ®é‡‡é›†å™¨
        collector = EnhancedLiteratureCollector()
        
        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        async def progress_callback(step: str, progress: int, details: dict = None):
            try:
                task.current_step = step
                task.progress_percentage = progress
                if details:
                    task.result = details
                db.commit()
                logger.info(f"ä»»åŠ¡ {task_id} è¿›åº¦æ›´æ–°: {step} ({progress}%)")
            except Exception as e:
                logger.warning(f"æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
        
        try:
            # æ‰§è¡Œé‡‡é›†
            result = await collector.collect_literature_with_screening(
                keywords=keywords,
                user=user,
                max_count=max_count,
                sources=sources,
                enable_ai_screening=True,
                progress_callback=progress_callback
            )
            
            # é‡‡é›†å®Œæˆï¼Œæ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = "completed"
            task.end_time = datetime.utcnow()
            task.current_step = "æ–‡çŒ®é‡‡é›†å®Œæˆ"
            task.progress_percentage = 100.0
            task.result = {
                "success": True,
                "total_collected": len(result.get("literature", [])),
                "quality_filtered": result.get("quality_filtered", 0),
                "with_pdf": result.get("with_pdf", 0),
                "statistics": result
            }
            
            db.commit()
            logger.info(f"æ–‡çŒ®é‡‡é›†ä»»åŠ¡ {task_id} å®Œæˆï¼Œé‡‡é›† {len(result.get('literature', []))} ç¯‡æ–‡çŒ®")
            
        finally:
            # å…³é—­é‡‡é›†å™¨èµ„æº
            await collector.close()
            
    except Exception as e:
        logger.error(f"æ–‡çŒ®é‡‡é›†ä»»åŠ¡å¼‚å¸¸: {e}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        try:
            task.status = "failed"
            task.end_time = datetime.utcnow()
            task.error_message = str(e)
            task.result = {"success": False, "error": str(e)}
            db.commit()
        except Exception as commit_error:
            logger.error(f"æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥: {commit_error}")
    
    finally:
        db.close()

async def start_literature_processing_task(task_id: int):
    """å¯åŠ¨æ–‡çŒ®å¤„ç†ä»»åŠ¡"""
    db = SessionLocal()
    
    try:
        task = db.query(Task).filter(Task.id == task_id).first()
        if not task:
            return
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        task.status = "running"
        task.started_at = datetime.utcnow()
        task.current_step = "åˆå§‹åŒ–æ–‡çŒ®å¤„ç†"
        task.progress_percentage = 0
        db.commit()
        
        # å‘é€WebSocketæ›´æ–°
        from app.services.stream_progress_service import StreamProgressService
        progress_service = StreamProgressService()
        await safe_broadcast_update(progress_service, task_id, {
            "type": "task_started",
            "task_id": task_id,
            "progress": 0,
            "current_step": "åˆå§‹åŒ–æ–‡çŒ®å¤„ç†"
        })
        
        # è·å–é¡¹ç›®å’Œæœªå¤„ç†æ–‡çŒ®
        project = db.query(Project).filter(Project.id == task.project_id).first()
        unprocessed_literature = db.query(Literature).filter(
            Literature.projects.any(id=task.project_id),
            Literature.is_parsed == False
        ).all()
        
        if not unprocessed_literature:
            task.status = "completed"
            task.error_message = "æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡çŒ®"
            db.commit()
            return
        
        # ç”Ÿæˆç»“æ„åŒ–æ¨¡æ¿
        # ä½¿ç”¨ç»Ÿä¸€çš„research_ai_serviceæ›¿ä»£AIServiceå®ä¾‹
        
        # å‡†å¤‡æ ·æœ¬æ–‡çŒ®æ•°æ®
        sample_literature = []
        for lit in unprocessed_literature[:5]:
            sample_literature.append({
                "title": lit.title,
                "abstract": lit.abstract or "",
                "authors": lit.authors or []
            })
        
        # ç”Ÿæˆæ¨¡æ¿
        template_result = await research_ai_service.generate_structure_template(
            project.research_direction or "é€šç”¨ç§‘ç ”", 
            sample_literature
        )
        
        if template_result["success"]:
            project.structure_template = template_result["template"]
            db.commit()
        
        # å¤„ç†æ¯ç¯‡æ–‡çŒ®
        pdf_processor = PDFProcessor()
        processed_count = 0
        
        for i, literature in enumerate(unprocessed_literature):
            try:
                logger.info(f"å¤„ç†æ–‡çŒ®: {literature.title[:50]}...")
                
                # å¦‚æœæœ‰PDFï¼Œå…ˆå¤„ç†PDF
                if literature.pdf_url or literature.pdf_path:
                    # å¤„ç†PDFæ–‡ä»¶
                    pdf_path = literature.pdf_path or literature.pdf_url
                    if pdf_path and os.path.exists(pdf_path):
                        try:
                            # ä½¿ç”¨PDFå¤„ç†å™¨å¤„ç†æ–‡ä»¶
                            result = await pdf_processor.process_pdf_with_segments(
                                pdf_path, project.structure_template
                            )
                            
                            if result["success"]:
                                # ä¿å­˜ç»“æ„åŒ–æ®µè½
                                segments = result.get("segments", [])
                                for segment_data in segments:
                                    segment = LiteratureSegment(
                                        literature_id=literature.id,
                                        segment_type=segment_data.get("segment_type", "general"),
                                        content=segment_data.get("content", ""),
                                        page_number=segment_data.get("page_number", 1),
                                        extraction_confidence=segment_data.get("confidence", 0.5),
                                        structured_data={
                                            "source": "mineru_processing",
                                            "processor_version": result.get("metadata", {}).get("version", "unknown")
                                        }
                                    )
                                    db.add(segment)
                                
                                # æ›´æ–°æ–‡çŒ®çŠ¶æ€
                                literature.is_parsed = True
                                literature.parsing_status = "completed"
                                literature.parsed_content = result["content"].get("text_content", "")
                                processed_count += 1
                                
                                logger.info(f"PDFå¤„ç†æˆåŠŸ: {literature.title[:50]} - {len(segments)} ä¸ªæ®µè½")
                            else:
                                # PDFå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯åˆ›å»ºæ®µè½
                                logger.warning(f"PDFå¤„ç†å¤±è´¥: {result.get('error', 'Unknown error')}")
                                await create_basic_segments(literature, db, project)
                                
                        except Exception as e:
                            logger.error(f"PDFå¤„ç†å¼‚å¸¸: {e}")
                            await create_basic_segments(literature, db, project)
                    else:
                        # PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                        await create_basic_segments(literature, db, project)
                else:
                    # æ²¡æœ‰PDFï¼ŒåŸºäºæ‘˜è¦å’Œæ ‡é¢˜ç”Ÿæˆæ®µè½
                    await create_basic_segments(literature, db, project)
                
                # æ›´æ–°è¿›åº¦
                progress_pct = 20 + (i + 1) / len(unprocessed_literature) * 70
                task.progress_percentage = progress_pct
                task.current_step = f"å·²å¤„ç† {i + 1}/{len(unprocessed_literature)} ç¯‡æ–‡çŒ®"
                
                # å‘é€è¿›åº¦æ›´æ–°
                if (i + 1) % 5 == 0:  # æ¯5ç¯‡æ›´æ–°ä¸€æ¬¡
                    db.commit()
                    await safe_broadcast_update(progress_service, task_id, {
                        "type": "task_progress",
                        "task_id": task_id,
                        "progress": progress_pct,
                        "current_step": f"å·²å¤„ç† {i + 1}/{len(unprocessed_literature)} ç¯‡æ–‡çŒ®",
                        "processed_count": i + 1,
                        "total_count": len(unprocessed_literature)
                    })
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡çŒ®å¤±è´¥: {literature.title[:50]} - {e}")
                literature.parsing_status = "failed"
        
        db.commit()
        
        # å®Œæˆä»»åŠ¡
        task.status = "completed"
        task.progress_percentage = 100.0
        task.current_step = "æ–‡çŒ®å¤„ç†å®Œæˆ"
        task.completed_at = datetime.utcnow()
        task.actual_duration = int((task.completed_at - task.started_at).total_seconds())
        task.result = {
            "processed_count": processed_count,
            "total_literature": len(unprocessed_literature),
            "success": True
        }
        db.commit()
        
        # å‘é€å®Œæˆæ¶ˆæ¯
        await safe_broadcast_update(progress_service, task_id, {
            "type": "task_completed",
            "task_id": task_id,
            "progress": 100,
            "current_step": "æ–‡çŒ®å¤„ç†å®Œæˆ",
            "result": {
                "processed_count": processed_count,
                "total_literature": len(unprocessed_literature),
                "message": f"æˆåŠŸå¤„ç† {processed_count} ç¯‡æ–‡çŒ®"
            }
        })
        
        logger.info(f"æ–‡çŒ®å¤„ç†ä»»åŠ¡å®Œæˆï¼Œå¤„ç†äº† {processed_count} ç¯‡æ–‡çŒ®")
        
    except Exception as e:
        logger.error(f"æ–‡çŒ®å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")
        
        task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            task.status = "failed"
            task.error_message = str(e)
            task.completed_at = datetime.utcnow()
            db.commit()
            
            # å‘é€å¤±è´¥æ¶ˆæ¯
            await safe_broadcast_update(progress_service, task_id, {
                "type": "task_failed",
                "task_id": task_id,
                "error": str(e)
            })
    
    finally:
        db.close()

async def start_experience_generation_task(task_id: int, research_question: str):
    """å¯åŠ¨ç»éªŒç”Ÿæˆä»»åŠ¡"""
    db = SessionLocal()
    
    try:
        task = db.query(Task).filter(Task.id == task_id).first()
        if not task:
            return
        
        task.status = "running"
        task.current_step = "å‡†å¤‡ç»éªŒç”Ÿæˆ"
        db.commit()
        
        # è·å–é¡¹ç›®æ–‡çŒ®æ®µè½
        literature_segments = db.query(LiteratureSegment).join(Literature).filter(
            Literature.projects.any(id=task.project_id)
        ).all()
        
        if not literature_segments:
            task.status = "failed"
            task.error_message = "æ²¡æœ‰å¯ç”¨çš„æ–‡çŒ®æ®µè½"
            db.commit()
            return
        
        # å¯åŠ¨ç»éªŒå¢å¼ºå¼•æ“
        experience_engine = EnhancedExperienceEngine(db)
        
        result = await experience_engine.run_experience_enhancement(
            task.project_id,
            research_question,
            literature_segments,
            task_id
        )
        
        if result["success"]:
            task.status = "completed"
            task.result = result
        else:
            task.status = "failed"
            task.error_message = result.get("error", "ç»éªŒç”Ÿæˆå¤±è´¥")
        
        db.commit()
        
    except Exception as e:
        logger.error(f"ç»éªŒç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
        
        task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            task.status = "failed"
            task.error_message = str(e)
            db.commit()
    
    finally:
        db.close()

async def build_literature_index(project_id: int, task_id: str, user_id: int):
    """æ„å»ºæ–‡çŒ®åº“ç´¢å¼•çš„åå°ä»»åŠ¡"""
    db = SessionLocal()
    
    try:
        # è·å–é¡¹ç›®ä¿¡æ¯
        project = db.query(Project).filter(Project.id == project_id).first()
        if not project:
            logger.error(f"é¡¹ç›®ä¸å­˜åœ¨: {project_id}")
            return
        
        logger.info(f"å¼€å§‹æ„å»ºé¡¹ç›® {project_id} çš„æ–‡çŒ®ç´¢å¼•ï¼Œä»»åŠ¡ID: {task_id}")
        
        # å‘é€WebSocketæ›´æ–°
        from app.services.stream_progress_service import StreamProgressService
        progress_service = StreamProgressService()
        progress_service.broadcast_project_update(project_id, {
            "type": "indexing_started",
            "task_id": task_id,
            "estimated_time": f"{len(project.literature) * 2}-{len(project.literature) * 5} ç§’"
        })
        
        # è·å–æ‰€æœ‰æ–‡çŒ®æ®µè½
        literature_segments = db.query(LiteratureSegment).join(Literature).filter(
            Literature.projects.any(id=project_id)
        ).all()
        
        if not literature_segments:
            # ç´¢å¼•å¤±è´¥ - æ²¡æœ‰æ®µè½æ•°æ®
            project.status = 'error'
            db.commit()
            
            progress_service.broadcast_project_update(project_id, {
                "type": "indexing_failed",
                "error": "æ²¡æœ‰å¯ç”¨çš„æ–‡çŒ®æ®µè½æ•°æ®ï¼Œè¯·å…ˆå¤„ç†æ–‡çŒ®"
            })
            return
        
        total_segments = len(literature_segments)
        logger.info(f"æ‰¾åˆ° {total_segments} ä¸ªæ–‡çŒ®æ®µè½ï¼Œå¼€å§‹æ„å»ºç´¢å¼•")
        
        # æ¨¡æ‹Ÿç´¢å¼•æ„å»ºè¿‡ç¨‹
        for i, segment in enumerate(literature_segments):
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„å‘é‡åŒ–å’Œç´¢å¼•æ„å»ºé€»è¾‘
            # ä¾‹å¦‚ï¼šç”Ÿæˆembeddingsï¼Œå­˜å‚¨åˆ°vectoræ•°æ®åº“ç­‰
            
            # æ›´æ–°è¿›åº¦
            progress = int((i + 1) / total_segments * 100)
            
            if (i + 1) % 10 == 0 or i == total_segments - 1:  # æ¯10ä¸ªæ®µè½æˆ–æœ€åä¸€ä¸ªæ›´æ–°ä¸€æ¬¡
                progress_service.broadcast_project_update(project_id, {
                    "type": "indexing_progress",
                    "progress": progress
                })
                logger.info(f"ç´¢å¼•è¿›åº¦: {i + 1}/{total_segments} ({progress}%)")
        
        # ç´¢å¼•æ„å»ºå®Œæˆ
        project.status = 'indexed'
        project.indexed_at = datetime.utcnow()
        project.index_version = 1  # å¯ä»¥ç”¨äºç‰ˆæœ¬æ§åˆ¶
        db.commit()
        
        # å‘é€å®Œæˆæ¶ˆæ¯
        progress_service.broadcast_project_update(project_id, {
            "type": "indexing_completed",
            "segments_indexed": total_segments
        })
        
        logger.info(f"é¡¹ç›® {project_id} ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…±ç´¢å¼• {total_segments} ä¸ªæ®µè½")
        
    except Exception as e:
        logger.error(f"ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        
        # æ›´æ–°é¡¹ç›®çŠ¶æ€ä¸ºé”™è¯¯
        try:
            project = db.query(Project).filter(Project.id == project_id).first()
            if project:
                project.status = 'error'
                db.commit()
                
                # å‘é€å¤±è´¥æ¶ˆæ¯
                progress_service.broadcast_project_update(project_id, {
                    "type": "indexing_failed",
                    "error": str(e)
                })
        except Exception as commit_error:
            logger.error(f"æ›´æ–°é¡¹ç›®çŠ¶æ€å¤±è´¥: {commit_error}")

    finally:
        db.close()


async def download_and_process_pdf_task(literature_id: int, user_id: int):
    """
    ä»ResearchRabbitè‡ªåŠ¨ä¸‹è½½PDFå¹¶å¤„ç†çš„åå°ä»»åŠ¡
    """
    db = SessionLocal()

    try:
        # è·å–æ–‡çŒ®è®°å½•
        literature = db.query(Literature).filter(Literature.id == literature_id).first()
        if not literature:
            logger.error(f"æœªæ‰¾åˆ°æ–‡çŒ®è®°å½• ID: {literature_id}")
            return

        logger.info(f"å¼€å§‹å¤„ç†æ–‡çŒ®PDF: {literature.title[:50]}...")

        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        literature.parsing_status = "processing"
        db.commit()

        # è·å–é¡¹ç›®ä¿¡æ¯ç”¨äºè¿›åº¦æ¨é€
        project = db.query(Project).join(Project.literature).filter(Literature.id == literature_id).first()
        project_id = project.id if project else None

        # 1. é€šè¿‡DOIè·å–PDFä¸‹è½½ä¿¡æ¯
        from app.services.research_rabbit_client import ResearchRabbitClient
        rabbit_client = ResearchRabbitClient()

        pdf_info = None
        if literature.doi:
            logger.info(f"é€šè¿‡DOIè·å–PDFä¿¡æ¯: {literature.doi}")
            pdf_info = await rabbit_client.get_pdf_info(literature.doi)

        if not pdf_info or not pdf_info.get("url_for_pdf"):
            logger.warning(f"æœªæ‰¾åˆ°PDFä¸‹è½½é“¾æ¥: {literature.title[:50]}")
            # ä½¿ç”¨åŸºæœ¬ä¿¡æ¯åˆ›å»ºæ®µè½
            await create_basic_segments(literature, db, project)
            literature.parsing_status = "completed"
            db.commit()

            # å‘é€å®Œæˆé€šçŸ¥
            if project_id:
                from app.services.stream_progress_service import stream_progress_service
                await safe_broadcast_update(stream_progress_service, 0, {
                    "type": "literature_processed",
                    "literature_id": literature_id,
                    "project_id": project_id,
                    "status": "no_pdf",
                    "message": f"æ–‡çŒ®å¤„ç†å®Œæˆï¼ˆæœªæ‰¾åˆ°PDFï¼‰: {literature.title[:50]}"
                })
            return

        # 2. ä¸‹è½½PDFæ–‡ä»¶
        logger.info(f"å¼€å§‹ä¸‹è½½PDF: {pdf_info['url_for_pdf']}")
        pdf_data = await rabbit_client.download_pdf(pdf_info["url_for_pdf"])

        if not pdf_data:
            logger.warning(f"PDFä¸‹è½½å¤±è´¥: {literature.title[:50]}")
            # ä½¿ç”¨åŸºæœ¬ä¿¡æ¯åˆ›å»ºæ®µè½
            await create_basic_segments(literature, db, project)
            literature.parsing_status = "completed"
            db.commit()

            # å‘é€å¤±è´¥é€šçŸ¥
            if project_id:
                from app.services.stream_progress_service import stream_progress_service
                await safe_broadcast_update(stream_progress_service, 0, {
                    "type": "literature_processed",
                    "literature_id": literature_id,
                    "project_id": project_id,
                    "status": "download_failed",
                    "message": f"PDFä¸‹è½½å¤±è´¥: {literature.title[:50]}"
                })
            return

        # 3. ä¿å­˜PDFæ–‡ä»¶
        import tempfile
        import os
        with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as temp_file:
            temp_file.write(pdf_data)
            temp_pdf_path = temp_file.name

        try:
            # 4. ä½¿ç”¨PDFProcessorå¤„ç†PDF
            from app.services.pdf_processor import PDFProcessor
            pdf_processor = PDFProcessor()

            logger.info(f"å¼€å§‹PDFå¤„ç†å’ŒMarkdownè½¬æ¢: {literature.title[:50]}")

            # ç”Ÿæˆç»“æ„æ¨¡æ¿ï¼ˆå¦‚æœéœ€è¦ï¼‰
            structure_template = None
            if project and project.structure_template:
                structure_template = project.structure_template

            # å¤„ç†PDFæ–‡ä»¶
            result = await pdf_processor.process_pdf_with_segments(
                temp_pdf_path,
                structure_template
            )

            if result.get("success"):
                # 5. ä¿å­˜å¤„ç†ç»“æœ
                segments_data = result.get("segments", [])

                # æ›´æ–°æ–‡çŒ®çŠ¶æ€
                literature.parsing_status = "completed"
                literature.is_downloaded = True
                literature.is_parsed = True
                literature.pdf_path = temp_pdf_path  # ä¿å­˜PDFè·¯å¾„

                # ä¿å­˜æ®µè½
                for segment_data in segments_data:
                    segment = LiteratureSegment(
                        literature_id=literature.id,
                        segment_type=segment_data.get("segment_type", "paragraph"),
                        content=segment_data.get("content", ""),
                        order=segment_data.get("order", 0),
                        page_number=segment_data.get("page_number"),
                        metadata=segment_data.get("metadata", {})
                    )
                    db.add(segment)

                db.commit()

                logger.info(f"PDFå¤„ç†æˆåŠŸ: {literature.title[:50]} - {len(segments_data)} ä¸ªæ®µè½")

                # å‘é€æˆåŠŸé€šçŸ¥
                if project_id:
                    from app.services.stream_progress_service import stream_progress_service
                    await safe_broadcast_update(stream_progress_service, 0, {
                        "type": "literature_processed",
                        "literature_id": literature_id,
                        "project_id": project_id,
                        "status": "success",
                        "segments_count": len(segments_data),
                        "message": f"PDFå¤„ç†æˆåŠŸ: {literature.title[:50]}"
                    })

            else:
                # PDFå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                logger.warning(f"PDFå¤„ç†å¤±è´¥: {result.get('error', 'Unknown error')}")
                await create_basic_segments(literature, db, project)
                literature.parsing_status = "completed"
                db.commit()

                # å‘é€å¤„ç†å¤±è´¥é€šçŸ¥
                if project_id:
                    from app.services.stream_progress_service import stream_progress_service
                    await safe_broadcast_update(stream_progress_service, 0, {
                        "type": "literature_processed",
                        "literature_id": literature_id,
                        "project_id": project_id,
                        "status": "processing_failed",
                        "message": f"PDFå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯: {literature.title[:50]}"
                    })

        finally:
            # æ¸…ç†ä¸´æ—¶PDFæ–‡ä»¶
            if os.path.exists(temp_pdf_path):
                try:
                    os.unlink(temp_pdf_path)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    except Exception as e:
        logger.error(f"PDFä¸‹è½½å¤„ç†ä»»åŠ¡å¤±è´¥ (æ–‡çŒ®ID: {literature_id}): {e}")

        # æ›´æ–°å¤±è´¥çŠ¶æ€
        literature = db.query(Literature).filter(Literature.id == literature_id).first()
        if literature:
            literature.parsing_status = "failed"
            db.commit()

            # å‘é€é”™è¯¯é€šçŸ¥
            project = db.query(Project).join(Project.literature).filter(Literature.id == literature_id).first()
            if project:
                from app.services.stream_progress_service import stream_progress_service
                await safe_broadcast_update(stream_progress_service, 0, {
                    "type": "literature_processed",
                    "literature_id": literature_id,
                    "project_id": project.id,
                    "status": "error",
                    "message": f"å¤„ç†å¤±è´¥: {str(e)[:100]}"
                })

    finally:
        db.close()